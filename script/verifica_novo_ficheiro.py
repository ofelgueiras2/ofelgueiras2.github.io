import requests
from bs4 import BeautifulSoup
import os

URL = "https://simuladorprecos.erse.pt/"
PASTA_DESTINO = "ERSE"

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64)"
}

def obter_url_zip():
    res = requests.get(URL, headers=headers)
    soup = BeautifulSoup(res.text, "html.parser")
    links = soup.find_all('a', class_='csvPath')
    
    for link in links:
        href = link.get('href', '')
        if href and "CSV.zip" in href and href != "#":
            return href
        
    print("‚ùå Nenhum link v√°lido ZIP encontrado.")
    return None

def main():
    url_zip = obter_url_zip()
    if not url_zip:
        return

    nome_ficheiro = url_zip.split("/")[-1].replace(" ", "_")
    caminho_ficheiro = os.path.join(PASTA_DESTINO, nome_ficheiro)

    if os.path.exists(caminho_ficheiro):
        print(f"‚úî J√° existe localmente: {nome_ficheiro}")
        return

    print(f"üÜï Novo ficheiro encontrado: {nome_ficheiro}")
    conteudo = requests.get(url_zip, headers=headers).content
    os.makedirs(PASTA_DESTINO, exist_ok=True)
    with open(caminho_ficheiro, "wb") as f:
        f.write(conteudo)
    print(f"‚úÖ Guardado em {caminho_ficheiro}")

if __name__ == "__main__":
    main()
